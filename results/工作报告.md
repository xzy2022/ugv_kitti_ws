# Phase 1: 环境搭建与数据特性解析 (Data Parsing & Sensor Analysis)

## 1. 工作摘要
本阶段完成了 KITTI Odometry 数据集的开发环境搭建与基础 I/O 模块开发。不同于简单的文件读取，本阶段重点深入分析了 Velodyne HDL-64E 的原始数据存储结构、激光发射时序特性，并据此设计了高效的数据预处理方案。

## 2. 核心产出
* **LiDARLoader 类封装**：
    * 实现了 `.bin` 二进制文件的解析接口。
    * 集成了**距离过滤 (Distance Filter)** 功能，有效剔除车身自遮挡盲区及远端噪声。
    * 设计了兼容 **Uniform (均匀)** 与 **Structured (结构化)** 的双模式降采样接口。
* **传感器物理特性验证**：
    * **存储顺序验证**：通过分析 Azimuth 与 Index 的关系，证实了 KITTI 原始数据采用 **Ring-Major (按线束存储)** 格式，而非 Time-Major。
    * **时序特性分析**：通过双轴可视化 (Dual-Axis Plotting)，揭示了激光雷达“微观锯齿波”与“宏观环境轮廓”的对应关系。
    * **线束分割算法**：开发了基于相位卷绕 (Phase Wrap-around) 的检测算法，成功识别并分割出 64 个独立的激光线束环。
* **可视化工具**：
    * 构建了基于 Matplotlib 的多视图可视化工具（BEV 视图、距离分布直方图、线束点数统计图）。

## 3. 关键发现 (Key Insights)
1.  **数据非均匀性**：原始点云在空间分布上具有极强的“近密远疏”特性，且 Z 轴分布呈现明显的层状结构。
2.  **采样策略优化**：
    * 传统的均匀切片采样 (`points[::N]`) 在 Ring-Major 数据上虽然高效，但在可视层面上可能导致扫描线断裂。
    * 提出的 **结构化降采样 (Structured Downsampling)** 方案（如 `Vert_step=2, Horiz_step=5`），能够模拟低线束雷达（如 32线/16线）效果，同时保留扫描线的几何连续性，更适合后续特征提取算法。
3.  **数据稳定性**：通过对连续 5 帧数据的突变索引分析，确认了雷达转速和点数具有较高的一致性，为后续建立静态索引表提供了依据。

## 4. 后续计划
基于本阶段解析出的高质量点云数据，下一阶段将引入 Calibration (外参) 与 Ground Truth (位姿真值)，重点攻克 **坐标系变换** 与 **位姿解算** 这一核心数学问题。

# Phase 2: 位姿解算与多传感器坐标系变换 (Pose & Coordinate Transformation)

## 1. 工作摘要
本阶段重点攻克了自动驾驶中最为核心的“定位与坐标系”问题。通过解析 KITTI 数据集的标定参数 ($Tr$) 和真值位姿 ($P$), 成功实现了从雷达坐标系 ($L$) 到相机坐标系 ($C$) 再到世界坐标系 ($W$) 的完整变换链路，并通过轨迹可视化验证了数学推导的正确性。

## 2. 核心产出
* **KittiPoseHandler 类封装**：
    * 实现了 `calib.txt` 和 `poses/xx.txt` 的解析接口，将原始数据转化为标准的 $4 \times 4$ 齐次变换矩阵。
    * 提供了 `get_pose_in_world(frame_id, sensor_type)` 高层接口，支持动态查询任意时刻、任意传感器（LiDAR/Camera）在世界系下的精确位姿。
* **坐标变换数学推导**：
    * 推导并验证了世界系下的雷达位姿公式：
        $$^{W}P_{L_t} = Tr^{-1} \times ^{C_0}P_{C_t} \times Tr$$
    * 明确了 KITTI 数据集中 Reference Frame ($C_0$) 与 World Frame 的定义关系，以及标定矩阵 $Tr$ ($T_{C\_L}$) 的物理含义。
* **多传感器轨迹可视化与验证**：
    * 利用 Matplotlib 3D 实现了 Camera 与 LiDAR 的双轨迹同图显示。
    * 通过 **Global View (全局)** 与 **Local Zoom (局部连线)** 两种视图，直观展示了传感器之间的刚体约束。
    * **物理一致性验证**：计算得出的“雷达-相机轨迹间距”与标定参数 $Tr$ 的平移向量模长完全一致（误差 $< 10^{-6}$ m），证明了坐标变换逻辑的严谨性。

## 3. 关键发现 (Key Insights)
1.  **位姿定义的陷阱**：KITTI 的真值位姿是基于 $0$ 号相机的，而点云是基于 Velodyne 雷达的。直接使用相机位姿来叠加点云会导致“车动点云不动”或严重的重影。必须引入 $Tr$ 矩阵进行修正。
2.  **刚体约束的可视化**：在宏观尺度下，不同传感器的轨迹几乎重合；但在微观尺度下，可以看到它们保持着恒定的相对位置（即标定外参），这为后续的多传感器融合提供了直观的信任基础。
3.  **矩阵乘法顺序**：在代码实现中，$T_{A\_B} \times T_{B\_C}$ 的左乘顺序至关重要，任何颠倒都会导致坐标系混乱。

## 4. 后续计划 (Phase 3 Preview)
解决了“车在哪里”的问题后，下一阶段将深入研究“车什么姿态”。计划引入欧拉角（Euler Angles）与四元数（Quaternions）的转换，探讨万向节死锁（Gimbal Lock）问题在非结构化道路场景下的潜在风险，为最终的点云拼接和建图打下坚实的理论基础。